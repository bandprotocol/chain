version: "3.7"

services:
  multi-validator1-node:
    build:
      context: .
      dockerfile: Dockerfile
    image: band-validator:latest
    networks:
      bandchain:
        ipv4_address: 172.18.0.11
    command: sh -c "chmod +x ./run.sh && ./run.sh validator1"

  multi-validator2-node:
    image: band-validator:latest
    networks:
      bandchain:
        ipv4_address: 172.18.0.12
    command: sh -c "chmod +x ./run.sh && ./run.sh validator2"

  multi-validator3-node:
    image: band-validator:latest
    networks:
      bandchain:
        ipv4_address: 172.18.0.13
    command: sh -c "chmod +x ./run.sh && ./run.sh validator3"

  multi-validator4-node:
    image: band-validator:latest
    networks:
      bandchain:
        ipv4_address: 172.18.0.14
    command: sh -c "chmod +x ./run.sh && ./run.sh validator4"

  emitter-node:
    image: band-validator:latest
    networks:
      bandchain:
    command: sh -c "chmod +x ./run.sh && ./run.sh emitter"

  query-node:
    image: band-validator:latest
    ports:
      - 26657:26657
      - 1317:1317
      - 9090:9090
    networks:
      bandchain:
        ipv4_address: 172.18.0.15
    command: sh -c "chmod +x ./run.sh && ./run.sh query-node"
      # rest-server:
      #   image: band-validator:latest
      #   networks:
      #     bandchain:
      #       ipv4_address: 172.18.0.20
      #   restart: always
      #   ports:
      #     - 1317:1317
      #   command: bandcli rest-server --laddr tcp://0.0.0.0:1317 --node tcp://172.18.0.15:26657 --chain-id bandchain --trust-node

  proxy-server:
    build:
      context: ./proxy
    image: proxy-server:latest
    networks:
      bandchain:
        ipv4_address: 172.18.0.99
    depends_on:
      - query-node
    ports:
      - 80:80

  proxy-ssl-server:
    build:
      context: ./proxy-ssl
    image: proxy-ssl-server:latest
    networks:
      bandchain:
        ipv4_address: 172.18.0.98
    depends_on:
      - query-node
    ports:
      - 443:443
      - 9091:9091
    volumes:
      - ./../ssl/cert.pem:/etc/nginx/ssl/cert.pem
      - ./../ssl/privkey.pem:/etc/nginx/ssl/privkey.pem

  postgres:
    image: postgres:12
    restart: always
    networks:
      bandchain:
        ipv4_address: 172.18.0.88
    environment:
      POSTGRES_PASSWORD: postgrespassword

  graphql-engine:
    build:
      context: ./hasura
    image: hasura:latest
    ports:
      - "5433:5433"
    depends_on:
      - "postgres"
    restart: always
    networks:
      bandchain:
        ipv4_address: 172.18.0.89
    environment:
      HASURA_GRAPHQL_DATABASE_URL: postgres://postgres:postgrespassword@172.18.0.88:5432/postgres
      HASURA_GRAPHQL_METADATA_DATABASE_URL: postgres://postgres:postgrespassword@172.18.0.88:5432/postgres
      HASURA_GRAPHQL_ENABLE_CONSOLE: "true"
      HASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, webhook-log, websocket-log, query-log
      HASURA_GRAPHQL_SERVER_HOST: 0.0.0.0
      HASURA_GRAPHQL_SERVER_PORT: 5433
      HASURA_GRAPHQL_STRINGIFY_NUMERIC_TYPES: "true"
    volumes:
      - ./docker-config/hasura-metadata:/hasura-metadata

  # TODO: Expose port to consume kafka from other
  zookeeper:
    image: wurstmeister/zookeeper
    # ports:
    #   - "2181:2181"
    networks:
      bandchain:
        ipv4_address: 172.18.0.30
  kafka:
    image: wurstmeister/kafka
    # ports:
    #   - "9092:9092"
    networks:
      bandchain:
        ipv4_address: 172.18.0.31
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.18.0.31
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_CREATE_TOPICS: test:1:1
      KAFKA_ZOOKEEPER_CONNECT: 172.18.0.30:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  flusher-init:
    build:
      context: flusher
    image: bandchain_flusher:latest
    networks:
      bandchain:
    command: sh -c "sleep 30 && python main.py init bandchain test replay --db postgres:postgrespassword@172.18.0.88:5432/postgres"

  flusher-daemon:
    image: bandchain_flusher:latest
    networks:
      bandchain:
    restart: always

networks:
  bandchain:
    ipam:
      driver: default
      config:
        - subnet: "172.18.0.0/16"
